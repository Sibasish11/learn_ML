{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MLOps\n",
    "\n",
    "Machine Learning Operations (**MLOps**) is the discipline of **managing and deploying machine learning models in production**. It combines the best practices of **DevOps** with the specific needs of **machine learning systems** ‚Äî including model training, versioning, deployment, and monitoring.\n",
    "\n",
    "MLOps aims to bridge the gap between **data science and IT operations**, ensuring that ML models are reliable, scalable, and maintainable over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand what MLOps is and why it matters.\n",
    "- Learn how MLOps fits within the ML lifecycle.\n",
    "- Explore the MLOps workflow and key components.\n",
    "- Discover tools and technologies used in modern MLOps pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è What is MLOps?\n",
    "\n",
    "Just like DevOps automates the software development lifecycle (SDLC), **MLOps automates the machine learning lifecycle (MLLC)** ‚Äî from **data collection to model deployment and monitoring**.\n",
    "\n",
    "MLOps ensures that ML models:\n",
    "- Are **repeatable** (reproducible training)\n",
    "- Are **automated** (CI/CD for ML)\n",
    "- Are **monitored** (track drift, performance)\n",
    "- Can be **scaled** (deploy to production environments)\n",
    "\n",
    "![MLOps Lifecycle](https://miro.medium.com/v2/resize:fit:1400/1*2EVKu0LQ1u8wYvT0o4h8gA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Components of MLOps\n",
    "\n",
    "1. **Data Engineering** : Gathering, cleaning, and transforming raw data.\n",
    "2. **Model Development** : Training, tuning, and validating ML models.\n",
    "3. **Model Versioning** : Tracking experiments and model versions.\n",
    "4. **Model Deployment** : Packaging and serving models for inference.\n",
    "5. **Model Monitoring** : Observing model performance and drift in production.\n",
    "6. **Continuous Integration/Deployment (CI/CD)** : Automating retraining and redeployment cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ The MLOps Lifecycle\n",
    "\n",
    "The general MLOps workflow looks like this:\n",
    "\n",
    "1. **Data Collection and Versioning**  ‚Üí DVC, Delta Lake\n",
    "2. **Model Training and Experiment Tracking**  ‚Üí MLflow, Weights & Biases\n",
    "3. **Model Packaging**  ‚Üí Docker, ONNX, TensorFlow Serving\n",
    "4. **Model Deployment**  ‚Üí REST API, FastAPI, Flask, Kubernetes\n",
    "5. **Monitoring and Feedback Loop**  ‚Üí Prometheus, Grafana, Evidently AI\n",
    "\n",
    "Each stage connects data scientists, ML engineers, and DevOps teams to ensure smooth delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Key Tools in MLOps\n",
    "\n",
    "| Stage | Common Tools |\n",
    "|--------|---------------|\n",
    "| Data Versioning | DVC, Delta Lake |\n",
    "| Experiment Tracking | MLflow, Weights & Biases, Neptune.ai |\n",
    "| Deployment | Docker, FastAPI, Flask, Kubernetes |\n",
    "| Monitoring | Prometheus, Grafana, Evidently AI |\n",
    "| Workflow Orchestration | Airflow, Kubeflow, Prefect |\n",
    "\n",
    "These tools work together to form **end-to-end ML pipelines** that are reproducible and automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Why MLOps Matters\n",
    "\n",
    "Without MLOps, most organizations face these challenges:\n",
    "- Models work in notebooks but fail in production.\n",
    "- Retraining models manually leads to inconsistencies.\n",
    "- Lack of visibility into how models perform over time.\n",
    "- Difficult to collaborate between teams.\n",
    "\n",
    "MLOps provides **structure, visibility, and automation**, enabling faster iteration and better model governance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Example: Traditional ML vs MLOps Workflow\n",
    "\n",
    "| Step | Traditional ML | MLOps Approach |\n",
    "|------|----------------|----------------|\n",
    "| Data Handling | Manual CSV updates | Data pipelines with DVC |\n",
    "| Model Training | Local Jupyter Notebook | Automated CI/CD with MLflow tracking |\n",
    "| Deployment | Manual Flask app | Containerized with Docker & deployed via Kubernetes |\n",
    "| Monitoring | Rarely monitored | Continuous performance tracking |\n",
    "\n",
    "The shift from manual to automated ML processes is the essence of MLOps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Example: MLOps Pipeline Overview (Code Simulation)\n",
    "\n",
    "```python\n",
    "from mlflow import log_metric, log_param, start_run\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "with start_run():\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = model.score(X_test, y_test)\n",
    "\n",
    "    log_param(\"n_estimators\", 100)\n",
    "    log_metric(\"accuracy\", acc)\n",
    "\n",
    "    joblib.dump(model, \"rf_model.pkl\")\n",
    "    print(f\"Model logged with accuracy: {acc:.4f}\")\n",
    "```\n",
    "\n",
    "‚úÖ This example demonstrates how MLOps tools like **MLflow** help track parameters, metrics, and artifacts automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ Summary\n",
    "\n",
    "- MLOps extends DevOps to manage ML workflows end-to-end.\n",
    "- It focuses on automation, reproducibility, scalability, and governance.\n",
    "- Key stages: **Data ‚Üí Model ‚Üí Deployment ‚Üí Monitoring**.\n",
    "- Tools: **MLflow, DVC, Docker, Kubernetes, Prometheus, Airflow.**\n",
    "\n",
    "Next, we‚Äôll dive deeper into **data versioning, experiment tracking, and deployment basics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Author:** *Sibasish Padhihari*  \n",
    "**Module:** `09-MLOps_and_Deployment`  \n",
    "**Next Notebook:** [01-Data_Versioning_with_DVC.ipynb](./01-Data_Versioning_with_DVC.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
