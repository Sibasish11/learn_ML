{
 "nbformat": 5,
 "nbformat_minor": 10,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Packaging and Persistence\n",
    "\n",
    "In this notebook, we'll learn how to **save, load, and package** machine learning models for reuse and deployment.\n",
    "\n",
    "We‚Äôll explore:\n",
    "- Different model persistence methods\n",
    "- Saving models using Pickle and Joblib\n",
    "- Packaging models with MLflow for production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Model Persistence Matters\n",
    "\n",
    "After training a machine learning model, you often need to **reuse** it for predictions without retraining.\n",
    "Model persistence allows you to:\n",
    "- Save trained models to disk\n",
    "- Load them later for inference\n",
    "- Share models across systems and environments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Method 1: Saving Model using Pickle\n",
    "\n",
    "`pickle` is a Python library that serializes (saves) and deserializes (loads) Python objects."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load model\n",
    "with open('rf_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify the loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(\"Sample predictions:\", y_pred[:5])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Method 2: Using Joblib\n",
    "\n",
    "`joblib` is optimized for saving **large NumPy arrays** and scikit learn models efficiently."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'rf_model.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_joblib_model = joblib.load('rf_model.joblib')\n",
    "\n",
    "print(\"‚úÖ Joblib model loaded successfully.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Method 3: Using MLflow Model Packaging\n",
    "\n",
    "MLflow allows models to be saved in a **standardized format**, making them easy to load and deploy across platforms.\n",
    "\n",
    "MLflow automatically saves model metadata (version, environment, and dependencies)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Log and save the model using MLflow\n",
    "with mlflow.start_run(run_name=\"RF_Model_Packaging\"):\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    print(\"‚úÖ Model logged with MLflow.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Loading MLflow Models\n",
    "MLflow models can be reloaded using the model URI path."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: load model from MLflow URI\n",
    "# model_uri = 'runs:/<run_id>/random_forest_model'\n",
    "# loaded_mlflow_model = mlflow.sklearn.load_model(model_uri)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Saving Model Metadata and Versioning\n",
    "\n",
    "It‚Äôs good practice to save **model metadata**, such as:\n",
    "- Training dataset details\n",
    "- Model parameters\n",
    "- Evaluation metrics\n",
    "\n",
    "This ensures transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "metadata = {\n",
    "    \"model_name\": \"RandomForestClassifier\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"accuracy\": float(model.score(X_test, y_test)),\n",
    "    \"features\": list(iris.feature_names)\n",
    "}\n",
    "\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"üóÇÔ∏è Metadata saved successfully.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Best Practices\n",
    "\n",
    "1. Use **Joblib** for large scikit-learn models.\n",
    "2. Store **model version and metadata** with every save.\n",
    "3. Use **MLflow** for team-based tracking and deployment.\n",
    "4. Maintain a **consistent file structure** for saved artifacts.\n",
    "5. Test **model loading** in a separate environment before deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "- Persist models using Pickle and Joblib\n",
    "- Log models with MLflow\n",
    "- Save model metadata for reproducibility\n",
    "- Prepare models for deployment\n",
    "\n",
    "Next ‚Üí `04-Model_Deployment_Basics.ipynb`, where we‚Äôll deploy models using Flask and MLflow serving."
   ]
  }
 ]
}

