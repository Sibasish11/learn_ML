{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization in Deep Neural Networks\n",
    "\n",
    "Training deep neural networks can be unstable due to **internal covariate shift** (changing input distributions for each layer during training).\n",
    "\n",
    "**Batch Normalization (BatchNorm)** helps by normalizing the activations of each layer, leading to:\n",
    "- Faster convergence\n",
    "- Better stability\n",
    "- Reduced overfitting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"Training data:\", x_train.shape)\n",
    "print(\"Test data:\", x_test.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_no_bn = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_no_bn.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "history_no_bn = model_no_bn.fit(x_train, y_train, epochs=5, batch_size=32,\n",
    "                                validation_data=(x_test, y_test), verbose=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_bn = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_bn.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history_bn = model_bn.fit(x_train, y_train, epochs=5, batch_size=32,\n",
    "                          validation_data=(x_test, y_test), verbose=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(history_no_bn.history['val_accuracy'], label='Without BatchNorm')\n",
    "plt.plot(history_bn.history['val_accuracy'], label='With BatchNorm')\n",
    "plt.title('Effect of Batch Normalization')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "- BatchNorm stabilizes and speeds up training.\n",
    "- Helps reduce overfitting by adding slight regularization.\n",
    "- Often allows use of higher learning rates.\n",
    "- Widely used in CNNs, RNNs, and Transformers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
