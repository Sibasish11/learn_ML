{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM Example\n",
    "\n",
    "This notebook demonstrates how to use **Bidirectional LSTMs**.\n",
    "\n",
    "ðŸ”¹ A Bidirectional LSTM processes the input sequence **forward** and **backward**.\n",
    "ðŸ”¹ Useful when **future context** is important (e.g., sentiment analysis, NER).\n",
    "\n",
    "Example: Sentence understanding â†’ Knowing the whole sentence helps predict meaning of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Embedding\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Toy Sequence Classification Dataset\n",
    "\n",
    "Weâ€™ll create binary sequences and classify them as 1 if the sum > 2.5, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, timesteps):\n",
    "    X = np.random.rand(n_samples, timesteps, 1)\n",
    "    y = (np.sum(X, axis=1) > (timesteps/2)).astype(int)\n",
    "    return X, y\n",
    "\n",
    "n_samples, timesteps = 1000, 10\n",
    "X, y = generate_data(n_samples, timesteps)\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64), input_shape=(timesteps, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on New Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.rand(1, timesteps, 1)\n",
    "pred = model.predict(sample)\n",
    "print(\"Input sequence sum:\", np.sum(sample))\n",
    "print(\"Predicted class (probability):\", pred[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
