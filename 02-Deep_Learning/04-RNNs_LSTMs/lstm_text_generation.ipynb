{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Text Generation\n",
    "\n",
    "In this notebook, we'll build an **LSTM-based text generator**. LSTMs are excellent for sequence tasks because they can remember long-term dependencies.\n",
    "\n",
    "We'll use a simple text dataset to demonstrate how an LSTM can learn patterns in text and generate new sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "We’ll use a small text string to create a character-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello world this is an lstm text generator\"\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {c:i for i,c in enumerate(chars)}\n",
    "idx_to_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "seq_length = 10\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(len(text) - seq_length):\n",
    "    sequences.append(text[i:i+seq_length])\n",
    "    next_chars.append(text[i+seq_length])\n",
    "\n",
    "X = np.array([[char_to_idx[c] for c in seq] for seq in sequences])\n",
    "y = np.array([char_to_idx[c] for c in next_chars])\n",
    "\n",
    "print(\"Vocabulary size:\", len(chars))\n",
    "print(\"Number of sequences:\", len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(chars), output_dim=50, input_length=seq_length),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dense(len(chars), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text\n",
    "We’ll now use the trained LSTM to generate text by predicting one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, length=50):\n",
    "    generated = seed_text\n",
    "    for _ in range(length):\n",
    "        x_pred = np.array([[char_to_idx[c] for c in generated[-seq_length:]]])\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_idx = np.argmax(preds)\n",
    "        next_char = idx_to_char[next_idx]\n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n",
    "print(generate_text(\"hello worl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
