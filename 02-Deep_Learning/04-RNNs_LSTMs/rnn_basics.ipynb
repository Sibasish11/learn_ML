{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNN) Basics\n",
    "\n",
    "## 1. Introduction\n",
    "- RNNs are designed for **sequential data** like text, time-series, and speech.\n",
    "- Unlike feedforward networks, RNNs keep a **hidden state** that carries information from previous time steps.\n",
    "- Applications:\n",
    "  - Text generation\n",
    "  - Sentiment analysis\n",
    "  - Stock price prediction\n",
    "  - Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How RNN Works\n",
    "- At each time step, the RNN takes input $x_t$ and previous hidden state $h_{t-1}$.\n",
    "- Updates the hidden state $h_t$.\n",
    "- Produces an output $y_t$.\n",
    "\n",
    "$$\n",
    "h_t = f(Wx_t + Uh_{t-1} + b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: Simple RNN for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example toy dataset: sentences represented as integer sequences\n",
    "X = [\n",
    "    [1, 2, 3, 4],\n",
    "    [2, 3, 4, 5],\n",
    "    [3, 4, 5, 6],\n",
    "    [4, 5, 6, 7]\n",
    "]\n",
    "y = [0, 1, 0, 1]  # Binary labels\n",
    "\n",
    "X = pad_sequences(X, maxlen=6)\n",
    "y = np.array(y)\n",
    "\n",
    "# Define RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10, output_dim=8, input_length=6),\n",
    "    SimpleRNN(16, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Notes\n",
    "- RNNs process input **step by step**.\n",
    "- Hidden states capture **context from past inputs**.\n",
    "- Problem: **Vanishing gradients** â†’ makes it hard to learn long-term dependencies.\n",
    "- Solution: Advanced RNNs like **LSTM** and **GRU**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
