{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Pipeline\n",
    "\n",
    "This notebook demonstrates how to build a simple **object detection pipeline** using a pretrained model:\n",
    "1. Load pretrained Faster R-CNN\n",
    "2. Perform inference on sample images\n",
    "3. Visualize bounding boxes and labels\n",
    "\n",
    "We’ll use **torchvision**’s pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pretrained Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# COCO dataset class labels\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
    "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
    "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
    "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',\n",
    "    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\n",
    "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Inference on an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, threshold=0.5):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)[0]\n",
    "    \n",
    "    # Filter predictions by threshold\n",
    "    pred_boxes = predictions['boxes'].cpu().numpy()\n",
    "    pred_scores = predictions['scores'].cpu().numpy()\n",
    "    pred_classes = predictions['labels'].cpu().numpy()\n",
    "    \n",
    "    selected = [i for i, score in enumerate(pred_scores) if score > threshold]\n",
    "    pred_boxes = pred_boxes[selected]\n",
    "    pred_classes = pred_classes[selected]\n",
    "    pred_scores = pred_scores[selected]\n",
    "    \n",
    "    return image, pred_boxes, pred_classes, pred_scores\n",
    "\n",
    "def plot_predictions(image, boxes, classes, scores):\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image)\n",
    "    for i, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                 linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        label = f\"{COCO_INSTANCE_CATEGORY_NAMES[classes[i]]}: {scores[i]:.2f}\"\n",
    "        ax.text(xmin, ymin - 5, label, color='yellow', fontsize=12, backgroundcolor='black')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (replace with your own image path)\n",
    "# img, boxes, classes, scores = predict(\"sample.jpg\", threshold=0.7)\n",
    "# plot_predictions(img, boxes, classes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We used a **pretrained Faster R-CNN** for object detection.\n",
    "- The pipeline loads an image, runs inference, and plots detected objects with bounding boxes.\n",
    "- Can be extended for **custom datasets** using `torchvision`’s detection training API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
