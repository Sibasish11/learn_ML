{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Text Generation\n",
    "\n",
    "GPT (Generative Pre-trained Transformer) is an **autoregressive language model** developed by OpenAI. \n",
    "\n",
    "## Key Features:\n",
    "- Based on the **Transformer Decoder** architecture.\n",
    "- Trained on massive text data in a self-supervised way.\n",
    "- Predicts the **next word** in a sequence.\n",
    "- Can generate human-like text for tasks like chat, summarization, and story writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pretrained GPT-2 Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Text with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input prompt\n",
    "prompt_text = \"Artificial Intelligence will \"\n",
    "\n",
    "# Encode input\n",
    "inputs = tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "\n",
    "# Generate continuation\n",
    "outputs = model.generate(inputs, max_length=50, num_return_sequences=1, temperature=0.7, top_p=0.9)\n",
    "\n",
    "# Decode output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Output:\n",
    "```text\n",
    "Artificial Intelligence will change the future of technology and how we interact with machines. It has the potential to...\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è Output varies because GPT generates probabilistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Hugging Face Pipeline for Simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "result = generator(\"Machine learning is\", max_length=40, num_return_sequences=1)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- GPT is an autoregressive model for **text generation**.\n",
    "- Built using the **Transformer Decoder**.\n",
    "- Hugging Face `transformers` allows easy use of GPT-2.\n",
    "- Can be applied to creative writing, chatbots, summarization, and more.\n",
    "\n",
    "üëâ Next step: Try **fine-tuning GPT** on a custom dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
