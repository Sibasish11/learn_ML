{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability in Deep Learning\n",
    "\n",
    "Deep learning models are powerful but often work as **black boxes**, making it hard to understand how they make predictions. Model interpretability aims to make these models more **transparent and explainable**.\n",
    "\n",
    "In this notebook, we‚Äôll cover:\n",
    "- Saliency Maps\n",
    "- Grad-CAM\n",
    "- Integrated Gradients\n",
    "- Why interpretability is important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Objective\n",
    "- Understand how deep models make predictions.\n",
    "- Visualize which regions in an image most influence model decisions.\n",
    "- Build trust and accountability in AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Load and Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = tf.keras.utils.get_file('elephant.jpg', 'https://i.imgur.com/Bvro0YD.png')\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "plt.imshow(image.load_img(img_path))\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Saliency Maps\n",
    "Saliency maps visualize which pixels influence the output prediction most by computing gradients of the output with respect to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = tf.convert_to_tensor(x)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img_tensor)\n",
    "    preds = model(img_tensor)\n",
    "    top_index = tf.argmax(preds[0])\n",
    "    top_class = preds[:, top_index]\n",
    "\n",
    "grads = tape.gradient(top_class, img_tensor)[0]\n",
    "saliency = np.max(np.abs(grads), axis=-1)\n",
    "\n",
    "plt.imshow(saliency, cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.title('Saliency Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Grad-CAM Visualization\n",
    "Grad-CAM (Gradient-weighted Class Activation Mapping) highlights **which regions** in an image are most influential for a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model = tf.keras.models.Model([\n",
    "    model.inputs], [model.get_layer('block5_conv3').output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img_tensor)\n",
    "    loss = predictions[:, top_index]\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "conv_outputs = conv_outputs[0]\n",
    "heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "plt.matshow(heatmap)\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Overlay Grad-CAM on Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_orig = cv2.imread(img_path)\n",
    "heatmap_resized = cv2.resize(heatmap.numpy(), (img_orig.shape[1], img_orig.shape[0]))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "superimposed_img = cv2.addWeighted(img_orig, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Grad-CAM Overlay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Integrated Gradients (Optional)\n",
    "Integrated Gradients measure feature importance by integrating gradients from a baseline to the actual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tf_explain.core.integrated_gradients import IntegratedGradients\n",
    "    ig = IntegratedGradients()\n",
    "    grid = ig.explain((x, None), model, class_index=int(top_index))\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.title('Integrated Gradients')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Integrated Gradients not available:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "- **Saliency Maps** highlight pixel importance.\n",
    "- **Grad-CAM** shows the most influential image regions.\n",
    "- **Integrated Gradients** provide smooth attribution.\n",
    "\n",
    "These techniques make deep models more **interpretable**, helping ensure **transparency and trust** in AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
