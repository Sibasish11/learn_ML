{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Networks (GCN)\n",
    "\n",
    "In this notebook, we‚Äôll dive deeper into **Graph Convolutional Networks (GCN)** : one of the most popular architectures in Graph Neural Networks (GNNs). GCNs extend the concept of convolution to non-Euclidean data like graphs.\n",
    "\n",
    "They were introduced in the paper: **‚ÄúSemi-Supervised Classification with Graph Convolutional Networks‚Äù (Kipf & Welling, 2017)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Understand the GCN layer operation and intuition.\n",
    "- Implement a GCN from scratch using PyTorch Geometric.\n",
    "- Train and evaluate GCN on the Cora citation dataset.\n",
    "- Visualize the learned node embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 1. Understanding GCN Layer Operation\n",
    "\n",
    "The GCN layer updates each node‚Äôs representation by aggregating and transforming information from its neighbors.\n",
    "\n",
    "The core operation is defined as:\n",
    "\n",
    "\\[\n",
    "H^{(l+1)} = \\sigma (\\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} H^{(l)} W^{(l)})\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\tilde{A} = A + I \\): adjacency matrix with self-loops\n",
    "- \\( \\tilde{D} \\): degree matrix of \\( \\tilde{A} \\)\n",
    "- \\( H^{(l)} \\): node features at layer *l*\n",
    "- \\( W^{(l)} \\): weight matrix\n",
    "- \\( \\sigma \\): non-linear activation (e.g., ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò 3. Load the Dataset (Cora)\n",
    "\n",
    "The **Cora dataset** is widely used for node classification in citation networks.\n",
    "- Nodes represent papers.\n",
    "- Edges represent citation links.\n",
    "- Each node has a feature vector and a class label."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset = Planetoid(root='data/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print('Number of nodes:', data.num_nodes)\n",
    "print('Number of features:', data.num_features)\n",
    "print('Number of edges:', data.num_edges)\n",
    "print('Number of classes:', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è 4. Define the GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ 5. Train the GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(201):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "out = model(data)\n",
    "pred = out.argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ 7. Visualize Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "out = model(data)\n",
    "z = out.detach().numpy()\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "z_2d = tsne.fit_transform(z)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(z_2d[:,0], z_2d[:,1], c=data.y, cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© 8. Key Insights\n",
    "- GCNs generalize the concept of convolution to graphs.\n",
    "- Each node updates its features based on its neighbors.\n",
    "- GCNs can be applied to various tasks: node classification, link prediction, and graph classification.\n",
    "- Adding more layers can lead to **over-smoothing**, where node representations become indistinguishable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Next Steps\n",
    "- Learn about **Graph Attention Networks (GAT)** for attention-based neighbor weighting.\n",
    "- Explore **GraphSAGE** for inductive learning on unseen nodes.\n",
    "- Apply GCNs on custom graph data (e.g., molecular, social)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
