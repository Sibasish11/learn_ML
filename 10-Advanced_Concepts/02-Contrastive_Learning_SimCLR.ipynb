{
 "nbformat": 5,
 "nbformat_minor": 1,
 "metadata": {
  "colab": {
   "name": "02-Contrastive_Learning_SimCLR.ipynb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning with SimCLR\n",
    "\n",
    "In this notebook, we‚Äôll explore **SimCLR (Simple Framework for Contrastive Learning of Visual Representations)** : one of the most influential approaches in **self-supervised learning (SSL)**.\n",
    "\n",
    "The key idea: *learn useful image representations by comparing similar and dissimilar image pairs : without using labels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò 1. What is Contrastive Learning?\n",
    "\n",
    "Contrastive Learning aims to bring **similar (positive)** pairs close together and push **dissimilar (negative)** pairs apart in the latent space.\n",
    "\n",
    "SimCLR is a framework that makes this idea practical and scalable for vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Core Components of SimCLR\n",
    "\n",
    "SimCLR has **four main components:**\n",
    "\n",
    "1. **Data Augmentation:** Create two different augmented versions of the same image.\n",
    "2. **Encoder Network:** A CNN (often ResNet) extracts representations.\n",
    "3. **Projection Head:** A small MLP that maps embeddings to a contrastive space.\n",
    "4. **Contrastive Loss (NT-Xent):** Encourages similar views to have high similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 3. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è 4. Data Augmentation for Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform_simclr = T.Compose([\n",
    "    T.RandomResizedCrop(size=32),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([T.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CIFAR10(root='./data', download=True, transform=transform_simclr)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© 5. Building the SimCLR Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_model='resnet18', projection_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = models.__dict__[base_model](pretrained=False)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        \n",
    "        # Projection head\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return h, z"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ 6. Contrastive Loss (NT-Xent)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    batch_size = z_i.shape[0]\n",
    "    z = torch.cat([z_i, z_j], dim=0)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "\n",
    "    # Mask self-similarity\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool).to(z.device)\n",
    "    sim = sim[~mask].view(2 * batch_size, -1)\n",
    "\n",
    "    positives = torch.cat([torch.diag(sim, batch_size), torch.diag(sim, -batch_size)])\n",
    "    nominator = torch.exp(positives / temperature)\n",
    "    denominator = torch.sum(torch.exp(sim / temperature), dim=1)\n",
    "    loss = -torch.log(nominator / denominator).mean()\n",
    "    return loss"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop (Simplified Example)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimCLR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1):  # keep it short for demo\n",
    "    for (x, _) in dataloader:\n",
    "        x_i = transform_simclr(x)\n",
    "        x_j = transform_simclr(x)\n",
    "\n",
    "        x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "        _, z_i = model(x_i)\n",
    "        _, z_j = model(x_j)\n",
    "\n",
    "        loss = nt_xent_loss(z_i, z_j)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}] Loss: {loss.item():.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "- SimCLR learns without labels by comparing augmented views.\n",
    "- The **contrastive loss** encourages similar representations for the same image.\n",
    "- Trained embeddings can later be fine tuned for classification tasks.\n",
    "\n",
    "Next ‚Üí `03-Pretext_Tasks_in_Self_Supervised_Learning.ipynb`"
   ]
  }
 ]
}

