{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Supervised Learning Basics\n",
    "\n",
    "**Self-supervised learning (SSL)** is one of the most revolutionary ideas in modern machine learning. It allows models to learn **useful representations** of data without the need for manual labeling.\n",
    "\n",
    "In SSL, the system creates its own supervision from the data : learning from **pseudo-labels** or **pretext tasks**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "- Understand what self supervised learning is and why it matters.\n",
    "- Learn about common SSL tasks in vision and NLP.\n",
    "- Implement a simple example of contrastive learning using images.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç What is Self-Supervised Learning?\n",
    "\n",
    "In traditional **supervised learning**, models require labeled data, like:\n",
    "\n",
    "| Input | Label |\n",
    "|--------|--------|\n",
    "| üê∂ Dog image | ‚ÄúDog‚Äù |\n",
    "| üê± Cat image | ‚ÄúCat‚Äù |\n",
    "\n",
    "But labeling data is expensive and time-consuming.\n",
    "\n",
    "Self supervised learning solves this by using the **data itself as supervision**. The model generates *pseudo labels* automatically.\n",
    "\n",
    "For example:\n",
    "- Mask part of an image and ask the model to predict the missing region.\n",
    "- Mask words in a sentence and predict the masked tokens (like in **BERT**).\n",
    "- Compare different views (augmentations) of the same data point and make their embeddings similar (**Contrastive Learning**).\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Common Self-Supervised Learning Tasks\n",
    "\n",
    "| Domain | Task | Example |\n",
    "|---------|------|----------|\n",
    "| **Vision** | Image colorization | Predict colors from grayscale images |\n",
    "| | Rotation prediction | Predict rotation angle (0¬∞, 90¬∞, 180¬∞, 270¬∞) |\n",
    "| | Contrastive learning | SimCLR, MoCo, BYOL |\n",
    "| **NLP** | Masked language modeling | Predict missing words (BERT) |\n",
    "| | Next sentence prediction | Determine if one sentence follows another |\n",
    "| | Autoencoding | Reconstruct input text |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Key Idea: Contrastive Learning\n",
    "\n",
    "Contrastive learning teaches the model to bring **similar samples closer** and **push dissimilar ones apart** in the feature space.\n",
    "\n",
    "### Example:\n",
    "- Two augmented versions of the same image ‚Üí **positive pair**\n",
    "- Two images from different classes ‚Üí **negative pair**\n",
    "\n",
    "The model learns using a **contrastive loss function**, such as **InfoNCE loss**:\n",
    "\n",
    "$$ L = -\\log \\frac{\\exp(sim(z_i, z_j)/\\tau)}{\\sum_k \\exp(sim(z_i, z_k)/\\tau)} $$\n",
    "\n",
    "where:\n",
    "- \\( sim(z_i, z_j) \\): cosine similarity\n",
    "- \\( \\tau \\): temperature parameter\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Example: Simple Contrastive Learning with Augmented Images\n",
    "\n",
    "Let's see a minimal PyTorch implementation to illustrate the concept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define simple augmentations\n",
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(32),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.CIFAR10(root=\"./data\", download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*32*3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Cosine similarity loss (contrastive-like)\n",
    "def contrastive_loss(z_i, z_j, temperature=0.5):\n",
    "    sim = torch.nn.functional.cosine_similarity(z_i, z_j)\n",
    "    return 1 - sim.mean()\n",
    "\n",
    "encoder = Encoder()\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "for imgs, _ in loader:\n",
    "    # Two augmented views of same images\n",
    "    aug1 = imgs + 0.05 * torch.randn_like(imgs)\n",
    "    aug2 = imgs + 0.05 * torch.randn_like(imgs)\n",
    "    z_i = encoder(aug1)\n",
    "    z_j = encoder(aug2)\n",
    "    loss = contrastive_loss(z_i, z_j)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "\n",
    "print(f\"Contrastive loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ Real World Applications\n",
    "- **Vision Transformers (ViT)** pre-trained with self supervised learning.\n",
    "- **BERT**, **GPT**, and **SimCLR** are all based on self supervised principles.\n",
    "- Used in **medical imaging**, **speech recognition**, and **recommendation systems**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "- Self supervised learning allows models to **learn from unlabeled data**.\n",
    "- Core idea: **create tasks where the input itself provides supervision**.\n",
    "- Common techniques include **contrastive learning**, **masked prediction**, and **autoencoding**.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next: Meta Learning Basics ‚Üí `02-Meta_Learning_Basics.ipynb`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
