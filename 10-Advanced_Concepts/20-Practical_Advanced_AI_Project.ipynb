{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Advanced AI Project\n",
    "\n",
    "In this notebook, we‚Äôll build a **complete advanced AI pipeline** : from data processing and model training to explainability and deployment. \n",
    "\n",
    "This capstone project combines concepts from previous modules like:\n",
    "- Transfer Learning\n",
    "- Explainable AI (XAI)\n",
    "- Model Compression\n",
    "- Deployment and Monitoring\n",
    "\n",
    "Let‚Äôs demonstrate this using an **image classification problem** : classifying images from the CIFAR-10 dataset using a fine tuned CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Project Workflow\n",
    "\n",
    "1. Load and preprocess CIFAR-10 data\n",
    "2. Fine-tune a pre-trained model (ResNet18)\n",
    "3. Evaluate the model using advanced metrics\n",
    "4. Apply explainability tools (LIME / Grad-CAM)\n",
    "5. Compress and optimize the model\n",
    "6. Deploy using FastAPI (conceptual overview)\n",
    "7. Conclude with key learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = trainset.classes\n",
    "print('Classes:', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 2. Fine-tuning a Pre-trained Model (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze base layers\n",
    "\n",
    "# modify final layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2  # use small number for demo\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 4. Evaluation and Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Grad-CAM Visualization (Model Explainability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "target_layer = model.layer4[-1]\n",
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "input_tensor = images[0:1].to(device)\n",
    "\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(1)])\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "rgb_img = images[0].permute(1,2,0).numpy()\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "plt.imshow(visualization)\n",
    "plt.title('Grad-CAM Explanation')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™∂ 5. Model Compression and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_model_path = 'compressed_resnet18.pth'\n",
    "torch.save(model.state_dict(), compressed_model_path)\n",
    "print('‚úÖ Model saved and ready for deployment!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê 6. Deployment with FastAPI (Concept Overview)\n",
    "\n",
    "Example API structure:\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, UploadFile\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "app = FastAPI()\n",
    "model = torch.load('compressed_resnet18.pth')\n",
    "\n",
    "@app.post('/predict')\n",
    "async def predict(file: UploadFile):\n",
    "    img = Image.open(file.file)\n",
    "    # preprocess and predict\n",
    "    return {\"prediction\": \"cat\"}\n",
    "```\n",
    "\n",
    "Deploy via Docker or cloud services like AWS, GCP, or Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ 7. Key Learnings\n",
    "\n",
    "- Combined advanced concepts: transfer learning, explainability, and deployment.\n",
    "- Used **Grad-CAM** for model transparency.\n",
    "- Saved and compressed the model for edge use.\n",
    "- Prepared an API-based deployment setup.\n",
    "\n",
    "**This project concludes the Advanced Concepts module and ties together all core ML to MLOps skills.** üéì"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
