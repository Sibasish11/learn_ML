{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI Basics\n",
    "\n",
    "### üéØ Objective\n",
    "This notebook introduces **Generative AI (GenAI)** : a field of machine learning where models learn to **generate new data** similar to what they were trained on.\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- What generative AI is and how it differs from discriminative AI.\n",
    "- Major types of generative models (VAE, GANs, Diffusion models, Transformers).\n",
    "- How to build a simple **Variational Autoencoder (VAE)** to generate new samples.\n",
    "- Key evaluation metrics for generative models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 1. What is Generative AI?\n",
    "\n",
    "**Generative AI** refers to systems capable of creating new data : such as text, images, music, or code ‚Äî that mimic human creativity.\n",
    "\n",
    "In contrast to **discriminative models** (which learn decision boundaries), **generative models** learn the **data distribution** $P(X)$ or $P(X|Y)$.\n",
    "\n",
    "### Examples:\n",
    "- üñºÔ∏è Image Generation ‚Üí *Stable Diffusion, DALL¬∑E, Midjourney*\n",
    "- üìù Text Generation ‚Üí *GPT, Claude, Gemini*\n",
    "- üéµ Audio/Music Generation ‚Üí *Jukebox, MusicLM*\n",
    "- üé• Video Generation ‚Üí *Sora, Runway*\n",
    "\n",
    "Generative AI is the foundation of most modern **creative AI applications**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Types of Generative Models\n",
    "\n",
    "| Model Type | Core Idea | Example |\n",
    "|-------------|------------|----------|\n",
    "| **Autoencoders (AE)** | Learn compressed representations (latent space) | Denoising AE |\n",
    "| **Variational Autoencoders (VAE)** | Learn probability distribution in latent space | Image synthesis |\n",
    "| **Generative Adversarial Networks (GANs)** | Generator vs Discriminator game | DeepFake, StyleGAN |\n",
    "| **Diffusion Models** | Learn to reverse noise to data | Stable Diffusion |\n",
    "| **Transformers (LLMs)** | Sequence prediction-based generation | GPT, BERT, etc. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© 3. Variational Autoencoder (VAE)\n",
    "\n",
    "A **VAE** is a probabilistic generative model that learns to map data into a latent space, from which new samples can be generated.\n",
    "\n",
    "### VAE Structure:\n",
    "- **Encoder:** Maps input ‚Üí mean (Œº) and variance (œÉ¬≤) of latent distribution.\n",
    "- **Reparameterization Trick:** Sample z = Œº + œÉ * Œµ, where Œµ ~ N(0,1).\n",
    "- **Decoder:** Reconstructs data from latent variable z.\n",
    "\n",
    "![VAE Diagram](https://developers.google.com/machine-learning/gan/images/vae-diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc_mu = nn.Linear(400, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 400)\n",
    "        self.fc_out = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc_decode(z))\n",
    "        return torch.sigmoid(self.fc_out(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "vae = VAE()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ VAE Loss Function\n",
    "The loss combines two terms:\n",
    "1. **Reconstruction Loss** : how well the output matches the input.\n",
    "2. **KL Divergence Loss** : how close the latent distribution is to a standard normal distribution.\n",
    "\n",
    "$$ \\mathcal{L} = \\text{ReconstructionLoss} + KL( q(z|x) || p(z) ) $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Training loop (simplified)\n",
    "vae.train()\n",
    "for epoch in range(2):  # fewer epochs for demo\n",
    "    total_loss = 0\n",
    "    for data, _ in train_loader:\n",
    "        data = data.view(-1, 784)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader.dataset):.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé® Generate New Samples\n",
    "Once trained, we can sample random vectors from the latent space to generate new digits."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(16, 20)\n",
    "    samples = vae.decode(z).view(-1, 1, 28, 28)\n",
    "\n",
    "grid = torch.cat([torch.cat([samples[i*4 + j] for j in range(4)], dim=2) for i in range(4)], dim=1)\n",
    "plt.imshow(grid.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Generated Digits by VAE')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 4. Beyond VAEs ‚Äî Other Generative Models\n",
    "\n",
    "### üîπ Generative Adversarial Networks (GANs)\n",
    "- Two networks ‚Äî **Generator** and **Discriminator** ‚Äî compete.\n",
    "- Generator learns to fool the discriminator by generating realistic samples.\n",
    "- Popular in **image synthesis, upscaling, and deepfakes.**\n",
    "\n",
    "### üîπ Diffusion Models\n",
    "- Learn to reverse a process of adding noise step-by-step.\n",
    "- Used in **DALL¬∑E 2**, **Stable Diffusion**, **Imagen**.\n",
    "\n",
    "### üîπ Large Language Models (LLMs)\n",
    "- Predict the next token given context.\n",
    "- Used in **ChatGPT, Claude, Gemini**.\n",
    "\n",
    "### Comparison\n",
    "| Model | Pros | Cons |\n",
    "|--------|------|------|\n",
    "| VAE | Stable training, interpretable latent space | Blurry images |\n",
    "| GAN | Sharp outputs, realistic | Unstable training |\n",
    "| Diffusion | High fidelity | Slow inference |\n",
    "| Transformers | Great for sequences | Needs large data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ 5. Evaluating Generative Models\n",
    "Evaluating generative quality is subjective, but key metrics include:\n",
    "- **Inception Score (IS):** Measures how realistic and diverse images are.\n",
    "- **Fr√©chet Inception Distance (FID):** Measures distance between generated and real image distributions.\n",
    "- **Perplexity:** Used for text generation.\n",
    "- **Human evaluation:** Gold standard for creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "- **Generative AI** focuses on creating new data, unlike discriminative models that classify existing data.\n",
    "- **VAEs** learn latent distributions; **GANs** play an adversarial game; **Diffusion models** denoise step-by-step.\n",
    "- These models form the foundation of modern generative tools powering **AI art, chatbots, and creativity apps**.\n",
    "\n",
    "üöÄ **Next:** Try exploring `GAN_Basics.ipynb` or `Diffusion_Models.ipynb` to deepen your understanding of creative AI generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
