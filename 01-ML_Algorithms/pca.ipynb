{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is a **dimensionality reduction** technique that transforms data into a new coordinate system:\n",
    "- The first axis (**PC1**) captures the maximum variance.\n",
    "- The second axis (**PC2**) captures the next highest variance (orthogonal to PC1).\n",
    "- And so on...\n",
    "\n",
    "### Why PCA?\n",
    "- Reduce dataset dimensions while keeping most information.\n",
    "- Visualize high-dimensional data in 2D/3D.\n",
    "- Remove noise and redundancy.\n",
    "\n",
    "### Key Steps:\n",
    "1. Standardize data (mean=0, variance=1).\n",
    "2. Compute covariance matrix.\n",
    "3. Find eigenvalues & eigenvectors.\n",
    "4. Project data into new space (principal components).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (Digits dataset - 8x8 images)\n",
    "digits = load_digits()\n",
    "X = digits.data  # Flattened images\n",
    "y = digits.target\n",
    "\n",
    "print(\"Original shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA (keep 2 components for visualization)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Transformed shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA result\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', s=15)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Digits\")\n",
    "plt.title(\"PCA: Digits Dataset (2 Components)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "print(\"Explained variance ratio (first 2 PCs):\", pca.explained_variance_ratio_)\n",
    "print(\"Total variance explained (2 PCs):\", np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with more components (e.g., 50)\n",
    "pca_full = PCA(n_components=50)\n",
    "X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "\n",
    "plt.plot(np.cumsum(pca_full.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Choosing Optimal Number of Components\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "- PCA reduces dimensionality while preserving variance.\n",
    "- Often used before clustering or visualization.\n",
    "- Helps remove noise and redundancy.\n",
    "- Explained variance ratio tells how much information each component keeps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

