{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling and Normalization\n",
    "\n",
    "Feature scaling is an important preprocessing step because many machine learning models perform better when features are on a similar scale.\n",
    "\n",
    "In this notebook, we will cover:\n",
    "- Why scaling is needed\n",
    "- Standardization (Z-score normalization)\n",
    "- Min-Max Scaling (Normalization)\n",
    "- Robust Scaling\n",
    "- Comparing effects of scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "data = {\n",
    "    'Age': [18, 25, 30, 50, 80],\n",
    "    'Salary': [20000, 35000, 50000, 100000, 300000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Feature Scaling?\n",
    "\n",
    "- Algorithms like **KNN, SVM, Gradient Descent** are sensitive to scale.\n",
    "- Features with larger ranges (like `Salary`) can dominate features with smaller ranges (like `Age`).\n",
    "- Scaling ensures all features contribute equally to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardization (Z-score Normalization)\n",
    "- Formula:  \n",
    "  \\[ z = \\frac{x - \\mu}{\\sigma} \\]\n",
    "- Centers data around mean 0 with standard deviation 1.\n",
    "- Useful when data has both positive and negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_standardized = scaler.fit_transform(df)\n",
    "df_standardized = pd.DataFrame(df_standardized, columns=['Age', 'Salary'])\n",
    "df_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Min-Max Scaling (Normalization)\n",
    "- Formula:  \n",
    "  \\[ x' = \\frac{x - x_{min}}{x_{max} - x_{min}} \\]\n",
    "- Scales values into range [0, 1].\n",
    "- Useful when we want bounded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_minmax = scaler.fit_transform(df)\n",
    "df_minmax = pd.DataFrame(df_minmax, columns=['Age', 'Salary'])\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Robust Scaling\n",
    "- Uses median and interquartile range (IQR) instead of mean and standard deviation.\n",
    "- Formula:  \n",
    "  \\[ x' = \\frac{x - median}{IQR} \\]\n",
    "- Less sensitive to outliers compared to Standardization and Min-Max Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "df_robust = scaler.fit_transform(df)\n",
    "df_robust = pd.DataFrame(df_robust, columns=['Age', 'Salary'])\n",
    "df_robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing Different Scaling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Original_Age': df['Age'],\n",
    "    'Original_Salary': df['Salary'],\n",
    "    'Standardized_Age': df_standardized['Age'],\n",
    "    'MinMax_Age': df_minmax['Age'],\n",
    "    'Robust_Age': df_robust['Age']\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- **Standardization**: Mean = 0, Std = 1, good for normal distributions.\n",
    "- **Min-Max Scaling**: Scales data into [0, 1], useful for bounded features.\n",
    "- **Robust Scaling**: Uses median & IQR, good for data with outliers.\n",
    "\n",
    "ðŸ‘‰ Choice of scaling method depends on the algorithm and dataset characteristics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
