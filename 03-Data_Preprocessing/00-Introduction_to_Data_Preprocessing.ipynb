{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Preprocessing\n",
    "\n",
    "Data preprocessing is the **first and most important step** in any Machine Learning pipeline. \n",
    "\n",
    "In this notebook, we will cover:\n",
    "- Why preprocessing is needed\n",
    "- Handling missing values\n",
    "- Encoding categorical variables\n",
    "- Feature scaling\n",
    "- Splitting into train/test sets\n",
    "\n",
    "Let's start! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Data Preprocessing?\n",
    "\n",
    "Real-world datasets are often messy:\n",
    "- Missing or null values\n",
    "- Different data formats\n",
    "- Numerical values in different ranges\n",
    "- Categorical (textual) data\n",
    "\n",
    "Preprocessing helps clean and prepare the data so that Machine Learning models can learn effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'Age': [25, 30, np.nan, 35, 40],\n",
    "    'Salary': [50000, 60000, 55000, np.nan, 65000],\n",
    "    'Country': ['India', 'USA', 'India', 'UK', np.nan],\n",
    "    'Purchased': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing numerical values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])\n",
    "df['Salary'] = imputer.fit_transform(df[['Salary']])\n",
    "\n",
    "# Fill missing categorical values with mode (most frequent)\n",
    "df['Country'].fillna(df['Country'].mode()[0], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoding Categorical Variables\n",
    "- Label Encoding: Convert categories to numbers (useful for target column).\n",
    "- One-Hot Encoding: Create dummy variables (useful for features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for target column 'Purchased'\n",
    "le = LabelEncoder()\n",
    "df['Purchased'] = le.fit_transform(df['Purchased'])\n",
    "\n",
    "# One-Hot Encoding for 'Country'\n",
    "df = pd.get_dummies(df, columns=['Country'], drop_first=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling\n",
    "Different features might have different ranges (e.g., Age vs. Salary).\n",
    "\n",
    "Scaling brings them to a similar scale, which helps ML models perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting Dataset into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Purchased', axis=1)\n",
    "y = df['Purchased']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Features:\\n\", X_train)\n",
    "print(\"\\nTraining Labels:\\n\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- Dealt with missing values (mean & mode).\n",
    "- Encoded categorical features.\n",
    "- Scaled numerical features.\n",
    "- Split dataset into train/test sets.\n",
    "\n",
    "This is the **foundation of every ML pipeline**. Preprocessed data ensures your models learn correctly and perform better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
