{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) and TF-IDF\n",
    "\n",
    "**Objective:** Convert text data into numerical vectors that machine learning models can understand.\n",
    "\n",
    "---\n",
    "## Why Do We Need Feature Extraction?\n",
    "Machine learning models can't process raw text. We need to represent words as **numbers**. Two popular methods are:\n",
    "\n",
    "- **Bag of Words (BoW):** Counts the frequency of words.\n",
    "- **TF-IDF (Term Frequency–Inverse Document Frequency):** Weighs words by importance across documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bag of Words (BoW)\n",
    "\n",
    "BoW creates a vocabulary of all words in the dataset and counts occurrences in each document.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "| Document | Text |\n",
    "|-----------|------|\n",
    "| 1 | I love machine learning |\n",
    "| 2 | I love coding in Python |\n",
    "\n",
    "→ Vocabulary: `[I, love, machine, learning, coding, in, Python]`\n",
    "\n",
    "| Word | Doc1 | Doc2 |\n",
    "|------|------|------|\n",
    "| I | 1 | 1 |\n",
    "| love | 1 | 1 |\n",
    "| machine | 1 | 0 |\n",
    "| learning | 1 | 0 |\n",
    "| coding | 0 | 1 |\n",
    "| in | 0 | 1 |\n",
    "| Python | 0 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"I love machine learning\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"\\nBoW Matrix:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Interpretation:** Each document becomes a numerical vector based on word frequency.\n",
    "\n",
    "### Pros\n",
    "- Simple and intuitive.\n",
    "- Works well for small datasets.\n",
    "\n",
    "### Cons\n",
    "- Ignores meaning and word order.\n",
    "- Large vocabulary = high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TF-IDF (Term Frequency–Inverse Document Frequency)\n",
    "\n",
    "TF-IDF improves BoW by reducing the weight of common words and increasing the weight of rare, informative words.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "\\[ TF-IDF = TF × IDF \\]\n",
    "\n",
    "Where:\n",
    "- **TF (Term Frequency):** How often a term appears in a document.\n",
    "- **IDF (Inverse Document Frequency):** How rare a term is across all documents.\n",
    "\n",
    "\\[ IDF = log(\\frac{N}{df}) \\]\n",
    "where *N* = total documents, *df* = number of documents containing the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(docs)\n",
    "\n",
    "print(\"Vocabulary:\", tfidf.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\\n\", X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **TF-IDF gives higher importance to unique terms** (like *machine* or *Python*), while common terms (*I*, *love*) get lower scores.\n",
    "\n",
    "---\n",
    "## Visualizing Word Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "df_tfidf.T.plot(kind='bar', figsize=(8,4))\n",
    "plt.title('TF-IDF Scores for Each Word')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparison Table\n",
    "\n",
    "| Feature | Bag of Words | TF-IDF |\n",
    "|----------|---------------|--------|\n",
    "| Meaning | Word counts | Weighted by importance |\n",
    "| Handles common words | ❌ No | ✅ Yes |\n",
    "| Computational cost | Low | Medium |\n",
    "| Works better for | Small datasets | Larger text corpora |\n",
    "\n",
    "---\n",
    "## Summary\n",
    "- **BoW** represents text with raw word counts.\n",
    "- **TF-IDF** adjusts weights based on word importance.\n",
    "- Both are essential before applying ML algorithms like Naive Bayes or SVM.\n",
    "\n",
    "---\n",
    " **Next:** `05-Word_Embeddings_Basics.ipynb` — Understand how to represent words as continuous vectors using embeddings!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
