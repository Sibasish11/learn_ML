{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection Pipeline\n",
    "\n",
    "**Objective:** Build an end-to-end spam detection model using **TF-IDF** and **Logistic Regression**.\n",
    "\n",
    "---\n",
    "## üß† 1Ô∏è‚É£ What is Spam Detection?\n",
    "\n",
    "Spam detection is a text classification problem where the goal is to determine whether a message/email is **spam (unwanted)** or **ham (legitimate)**.\n",
    "\n",
    "**Example:**\n",
    "- \"Win a FREE iPhone! Click here now!\" ‚Üí Spam üö´\n",
    "- \"Your meeting is scheduled for tomorrow at 10 AM.\" ‚Üí Ham ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è 2Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö 3Ô∏è‚É£ Create or Load Dataset\n",
    "\n",
    "For demonstration, we‚Äôll create a small sample dataset. In real-world applications, datasets like **SMS Spam Collection** (UCI) or **Enron Email Dataset** are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text': [\n",
    "        'Win a brand new car! Click here to claim.',\n",
    "        'Congratulations! You have won a lottery.',\n",
    "        'Please verify your account details to continue.',\n",
    "        'Hey, are we still on for the meeting tomorrow?',\n",
    "        'Don‚Äôt forget to submit your assignment by 5 PM.',\n",
    "        'Get free vouchers now!!!',\n",
    "        'Call me when you reach the office.',\n",
    "        'URGENT! Your mobile number has been selected!',\n",
    "        'Can you review my project report?',\n",
    "        'Exclusive offer just for you. Limited time only!'\n",
    "    ],\n",
    "    'label': ['spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üßπ 4Ô∏è‚É£ Preprocessing & Data Splitting\n",
    "\n",
    "We‚Äôll split our dataset into training and testing sets, then convert the text into numerical vectors using **TF-IDF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print('‚úÖ TF-IDF vectorization complete!')\n",
    "print('Vocabulary size:', len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ 5Ô∏è‚É£ Model Training (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print('‚úÖ Model training complete!')\n",
    "print('\\nAccuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä 6Ô∏è‚É£ Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham','Spam'], yticklabels=['Ham','Spam'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üí¨ 7Ô∏è‚É£ Test with Custom Messages\n",
    "You can now test your model on new messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    'Win cash prizes instantly! Click the link below.',\n",
    "    'Please send me the report by evening.',\n",
    "    'You have been selected for a free vacation!'\n",
    "]\n",
    "\n",
    "sample_features = vectorizer.transform(samples)\n",
    "predictions = model.predict(sample_features)\n",
    "\n",
    "for text, label in zip(samples, predictions):\n",
    "    emoji = 'üö´' if label == 'spam' else '‚úÖ'\n",
    "    print(f'{text} ‚Üí {label.upper()} {emoji}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è 8Ô∏è‚É£ Full Pipeline Integration\n",
    "\n",
    "In real-world applications, you can use **`Pipeline`** from scikit-learn to combine preprocessing and model training steps together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "spam_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "    ('model', LogisticRegression(max_iter=300))\n",
    "])\n",
    "\n",
    "spam_pipeline.fit(X_train, y_train)\n",
    "print('‚úÖ End-to-End Pipeline Ready!')\n",
    "print('Test Accuracy:', spam_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- Built an end-to-end **Spam Detection pipeline** using scikit-learn.\n",
    "- Used **TF-IDF** for text feature extraction.\n",
    "- Applied **Logistic Regression** for classification.\n",
    "- Evaluated using **confusion matrix** and **accuracy**.\n",
    "- Demonstrated **Pipeline automation**.\n",
    "\n",
    "---\n",
    "üìò **Next:** `09-News_Category_Classification.ipynb` ‚Äî Learn how to classify text into multiple categories!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

