{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Hyperparameter Tuning: Bayesian Optimization & Optuna\n",
    "\n",
    "So far, we explored **Grid Search** and **Random Search**. While useful, they can be inefficient for large search spaces.\n",
    "\n",
    "## Bayesian Optimization\n",
    "- Builds a probabilistic model (usually Gaussian Processes) of the objective function.\n",
    "- Chooses new hyperparameters to evaluate based on past results.\n",
    "- Efficient because it balances **exploration** (trying new values) and **exploitation** (focusing on promising regions).\n",
    "\n",
    "## Optuna\n",
    "- A modern optimization framework for hyperparameter tuning.\n",
    "- Uses techniques like Tree-structured Parzen Estimators (TPE).\n",
    "- Faster and more flexible than Grid/Random Search.\n",
    "- Supports pruning unpromising trials early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Optuna for Logistic Regression\n",
    "import optuna\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "\n",
    "    model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=500)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best CV Accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "- **Bayesian Optimization** guides search more intelligently than Grid/Random.\n",
    "- **Optuna** is a practical tool that implements advanced search strategies efficiently.\n",
    "- Optuna supports features like pruning, parallel execution, and visualization.\n",
    "\n",
    "Use these methods when working with **complex models** (e.g., neural networks, ensembles) and **large parameter spaces**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
