{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Model Evaluation\n",
    "\n",
    "When we build a machine learning model, it’s not enough to just train it. We need to **evaluate how well it performs** on unseen data. This process is called **model evaluation**.\n",
    "\n",
    "Why is this important?\n",
    "- To check if our model generalizes well.\n",
    "- To detect **overfitting** (model learns training data too well but fails on test data).\n",
    "- To compare different models and choose the best one.\n",
    "\n",
    "---\n",
    "## Key Ideas in Model Evaluation\n",
    "1. **Training vs Testing Data**  \n",
    "   - Train data → used to learn patterns.  \n",
    "   - Test data → used to measure performance on unseen data.  \n",
    "\n",
    "2. **Validation Set**  \n",
    "   Sometimes we split the dataset into three parts: train, validation, and test. Validation helps us tune hyperparameters before final evaluation.\n",
    "\n",
    "3. **Evaluation Metrics**  \n",
    "   - For classification → accuracy, precision, recall, F1-score, ROC-AUC.  \n",
    "   - For regression → MSE, RMSE, MAE, R²-score.  \n",
    "\n",
    "4. **Cross-Validation**  \n",
    "   Instead of one train-test split, cross-validation repeatedly splits the dataset to give a more reliable estimate.\n",
    "\n",
    "---\n",
    "## Example Workflow\n",
    "1. Split dataset into train and test.\n",
    "2. Train model on train set.\n",
    "3. Evaluate model on test set using proper metrics.\n",
    "4. Repeat with different models and choose the best-performing one.\n",
    "\n",
    "---\n",
    "In the next notebooks, we will dive deeper into **train-test splitting, cross-validation, evaluation metrics, and hyperparameter tuning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple train-test split and evaluation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
