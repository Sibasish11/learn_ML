{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA: Principal Component Analysis\n",
    "\n",
    "Principal Component Analysis (PCA) is one of the most popular **dimensionality reduction** techniques.\n",
    "\n",
    "It works by:\n",
    "- Finding new axes (principal components) that maximize variance.\n",
    "- Projecting data into a lower-dimensional space while keeping most information.\n",
    "\n",
    "## Why PCA?\n",
    "- Simplifies data without losing much information.\n",
    "- Reduces noise and redundancy.\n",
    "- Useful for visualization of high-dimensional datasets.\n",
    "- Speeds up machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA (2 Components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA with 2 principal components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df)\n",
    "\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "df_pca['target'] = iris.target\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance Ratio\n",
    "The explained variance tells us how much information (variance) is preserved by each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total Variance Explained:\", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing PCA Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_pca['PC1'], df_pca['PC2'], c=df_pca['target'], cmap='viridis', alpha=0.7)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA on Iris Dataset')\n",
    "plt.colorbar(label='Target Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Notes:\n",
    "- PCA reduced the **4D Iris dataset â†’ 2D** while preserving most variance.\n",
    "- `explained_variance_ratio_` tells us how much variance each PC captures.\n",
    "- Useful before clustering, classification, or visualization.\n",
    "- PCA is a **linear technique**, which may not capture nonlinear relationships (t-SNE or UMAP can help there)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
