{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Evaluation Metrics\n",
    "\n",
    "Since clustering is an unsupervised technique, we don’t have labels to directly measure accuracy. Instead, we use **clustering evaluation metrics** to assess the quality of clusters.\n",
    "\n",
    "## Common Metrics:\n",
    "- **Silhouette Score** → Measures how similar a point is to its own cluster vs other clusters.\n",
    "- **Calinski-Harabasz Index** → Ratio of between-cluster variance to within-cluster variance.\n",
    "- **Davies-Bouldin Index** → Average similarity measure of each cluster with its most similar cluster (lower is better).\n",
    "- **Adjusted Rand Index (ARI)** → Compares clustering with ground truth labels (if available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Score (ranges from -1 to 1, higher is better)\n",
    "sil_score = silhouette_score(X, labels)\n",
    "\n",
    "# Calinski-Harabasz Index (higher is better)\n",
    "ch_score = calinski_harabasz_score(X, labels)\n",
    "\n",
    "# Davies-Bouldin Index (lower is better)\n",
    "db_score = davies_bouldin_score(X, labels)\n",
    "\n",
    "# Adjusted Rand Index (compare with true labels, higher is better)\n",
    "ari_score = adjusted_rand_score(y, labels)\n",
    "\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "print(f\"Calinski-Harabasz Index: {ch_score:.3f}\")\n",
    "print(f\"Davies-Bouldin Index: {db_score:.3f}\")\n",
    "print(f\"Adjusted Rand Index: {ari_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Notes:\n",
    "- **Silhouette Score** close to 1 → clusters are well-separated.\n",
    "- **Calinski-Harabasz** higher → better-defined clusters.\n",
    "- **Davies-Bouldin** lower → better clusters.\n",
    "- **ARI** compares clustering to known labels if available; useful for benchmarking.\n",
    "- Choosing the right metric depends on whether ground truth labels are available and the shape of clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
