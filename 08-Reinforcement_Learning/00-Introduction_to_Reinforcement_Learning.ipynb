{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Introduction to Reinforcement Learning\n",
    "\n",
    "Reinforcement Learning (RL) is a type of **machine learning** where an agent learns to make decisions by **interacting with an environment**. The agent receives **rewards** or **penalties** based on its actions and learns the optimal strategy to maximize cumulative rewards.\n",
    "\n",
    "In simple words, RL is about *learning from trial and error*. Just like how humans learn from experience, an RL agent improves by exploring, failing, and adjusting its actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Concepts in RL\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|----------|\n",
    "| **Agent** | The learner or decision maker |\n",
    "| **Environment** | The world in which the agent operates |\n",
    "| **Action (A)** | The set of all possible moves the agent can make |\n",
    "| **State (S)** | A specific situation or configuration the agent is in |\n",
    "| **Reward (R)** | Feedback signal from the environment based on the action |\n",
    "| **Policy (œÄ)** | The agent‚Äôs strategy for choosing actions |\n",
    "| **Value Function (V)** | Expected long-term reward for a given state |\n",
    "| **Q-Function (Q)** | Expected long-term reward for a state-action pair |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© How Reinforcement Learning Works\n",
    "\n",
    "The RL process follows this cycle:\n",
    "\n",
    "1. The **agent** observes the current **state (S)**.\n",
    "2. The agent takes an **action (A)**.\n",
    "3. The **environment** gives a **reward (R)** and transitions to a new **state (S')**.\n",
    "4. The agent updates its **policy** to improve future decisions.\n",
    "\n",
    "This process continues until the task is complete or the episode ends.\n",
    "\n",
    "### üîÅ RL Loop Diagram\n",
    "```\n",
    "      +-------------+\n",
    "      |             |\n",
    "      |   AGENT     |\n",
    "      |             |\n",
    "      +-------------+\n",
    "           |   ^\n",
    "   Action  |   |  Reward\n",
    "           v   |\n",
    "      +-------------+\n",
    "      |             |\n",
    "      | ENVIRONMENT |\n",
    "      |             |\n",
    "      +-------------+\n",
    "```\n",
    "\n",
    "The goal is to find a **policy œÄ\*** that maximizes the *expected cumulative reward* over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Types of Reinforcement Learning\n",
    "\n",
    "1. **Positive Reinforcement:**\n",
    "   - Rewards desired behavior.\n",
    "   - Example: Increasing score for correct moves.\n",
    "\n",
    "2. **Negative Reinforcement:**\n",
    "   - Penalizes undesired actions.\n",
    "   - Example: Losing points for collisions in a driving simulation.\n",
    "\n",
    "3. **Exploration vs. Exploitation Trade-off:**\n",
    "   - **Exploration:** Trying new actions to discover better outcomes.\n",
    "   - **Exploitation:** Using the best-known actions to maximize rewards.\n",
    "\n",
    "A good RL agent must balance both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Example: Simple Environment Simulation\n",
    "\n",
    "Let‚Äôs implement a simple RL setup using **OpenAI Gym** ‚Äî a library that provides environments for training RL agents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install gymnasium --quiet"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create a simple environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode='human')\n",
    "\n",
    "# Reset environment to get initial state\n",
    "state, info = env.reset()\n",
    "\n",
    "for _ in range(100):  # run for 100 steps\n",
    "    action = env.action_space.sample()  # take random action\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "env.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- The **CartPole** environment simulates balancing a pole on a moving cart.\n",
    "- The agent takes random actions (left/right).\n",
    "- Each step provides a **reward** (for balancing) or ends if the pole falls.\n",
    "\n",
    "Later, we‚Äôll replace random actions with **smart decisions** learned through algorithms like **Q-Learning** and **DQN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Rewards and Returns\n",
    "\n",
    "At each step `t`, the agent gets a reward `R_t`. The **return (G_t)** is the total discounted reward:\n",
    "\n",
    "$$ G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots $$\n",
    "\n",
    "where:\n",
    "- $\\gamma$ is the **discount factor** (0 ‚â§ Œ≥ ‚â§ 1), determining how much future rewards matter.\n",
    "- Higher Œ≥ means the agent values long-term rewards more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ Applications of Reinforcement Learning\n",
    "\n",
    "‚úÖ **Robotics** ‚Äî Controlling robot arms, walking robots, and drones.\n",
    "‚úÖ **Gaming** ‚Äî RL agents beating humans in chess, Go, and Atari games.\n",
    "‚úÖ **Finance** ‚Äî Portfolio management and trading strategies.\n",
    "‚úÖ **Healthcare** ‚Äî Treatment planning and drug discovery.\n",
    "‚úÖ **Autonomous Vehicles** ‚Äî Self-driving decision systems.\n",
    "\n",
    "Reinforcement learning is the backbone of many **AI breakthroughs** like AlphaGo, OpenAI Five, and autonomous robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Summary\n",
    "\n",
    "- Reinforcement Learning teaches an agent to act in an environment using **trial and error**.\n",
    "- It optimizes behavior through **rewards and penalties**.\n",
    "- The main goal is to learn a **policy œÄ\*** that maximizes the long-term return.\n",
    "- Next, we‚Äôll dive into **Markov Decision Processes (MDPs)** ‚Äî the mathematical foundation of RL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **Next Notebook:** `01-Markov_Decision_Processes.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
