{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with ResNet50 on CIFAR-10\n",
    "\n",
    "In this notebook, we'll perform **transfer learning** using a **ResNet50** model pretrained on **ImageNet**, and fine-tune it on the **CIFAR-10** dataset.\n",
    "\n",
    "Transfer learning allows us to reuse features learned by powerful models trained on large datasets — saving time and improving accuracy on smaller tasks.\n",
    "\n",
    "### Steps we'll cover:\n",
    "1. Load and preprocess CIFAR-10\n",
    "2. Load pretrained ResNet50 model\n",
    "3. Freeze base layers & add custom head\n",
    "4. Compile and train model\n",
    "5. Evaluate and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Load and Preprocess CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# Resize images to 224x224 (ResNet input size)\n",
    "X_train_resized = tf.image.resize(X_train, (224, 224))\n",
    "X_test_resized = tf.image.resize(X_test, (224, 224))\n",
    "\n",
    "# Preprocess using ResNet's preprocessing\n",
    "X_train_prep = preprocess_input(X_train_resized)\n",
    "X_test_prep = preprocess_input(X_test_resized)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Load Pretrained ResNet50 Model\n",
    "- We'll use `include_top=False` to remove the fully connected layers.\n",
    "- Add our custom classifier on top."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_prep, y_train, validation_data=(X_test_prep, y_test), epochs=5, batch_size=64)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Fine-Tuning (Optional)\n",
    "Let's unfreeze the last few layers of ResNet to improve performance through fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fine_tune_history = model.fit(X_train_prep, y_train, validation_data=(X_test_prep, y_test), epochs=3, batch_size=64)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_prep, y_test, verbose=2)\n",
    "print(f\"\\n✅ Test Accuracy after fine-tuning: {test_acc*100:.2f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Visualize Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'] + fine_tune_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'] + fine_tune_history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'] + fine_tune_history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'] + fine_tune_history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pred_probs = model.predict(X_test_prep[:9])\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title(f\"True: {class_names[y_test[i][0]]}\\nPred: {class_names[pred_classes[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "- Used **ResNet50** pretrained on ImageNet.\n",
    "- Added a custom dense head for CIFAR-10 classification.\n",
    "- Achieved good accuracy in few epochs with minimal training.\n",
    "- Fine-tuning improved performance further.\n",
    "\n",
    "**Next steps:** Try other architectures like **VGG16**, **MobileNetV2**, or **EfficientNet** for comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
