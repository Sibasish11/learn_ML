{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection\n",
    "\n",
    "In this notebook, we’ll explore **YOLO (You Only Look Once)** — one of the most popular and efficient deep learning models for **real-time object detection**.\n",
    "\n",
    "We'll cover:\n",
    "- Understanding YOLO architecture\n",
    "- Installing and loading YOLOv5\n",
    "- Running inference on sample images\n",
    "- Training YOLOv5 on a custom dataset\n",
    "- Evaluating detection performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Introduction to YOLO\n",
    "\n",
    "**YOLO (You Only Look Once)** treats object detection as a **single regression problem**, predicting both bounding boxes and class probabilities directly from full images in one evaluation.\n",
    "\n",
    "**Key Features:**\n",
    "- Extremely fast (real-time capable)\n",
    "- High accuracy\n",
    "- Single-stage detector (vs. two-stage like Faster R-CNN)\n",
    "- Common versions: YOLOv3 → YOLOv5 → YOLOv8 (Ultralytics)\n",
    "\n",
    "**Architecture Overview:**\n",
    "1. Backbone (CSPDarknet) → Feature extraction\n",
    "2. Neck (PANet) → Feature fusion\n",
    "3. Head → Bounding box, class, confidence prediction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Setup and Installation\n",
    "\n",
    "We’ll use the official **Ultralytics YOLOv5** repository for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone YOLOv5 from GitHub (skip if already cloned)\n",
    "# !git clone https://github.com/ultralytics/yolov5.git\n",
    "# %cd yolov5\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import torch\n",
    "print('Using PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Load Pre-trained YOLOv5 Model\n",
    "\n",
    "YOLOv5 comes in different sizes (`s`, `m`, `l`, `x`):\n",
    "- `yolov5s` → Small, fast (good for demo)\n",
    "- `yolov5m` → Medium\n",
    "- `yolov5l` → Large\n",
    "- `yolov5x` → Extra large, more accurate\n",
    "\n",
    "We’ll use **`yolov5s`** (pre-trained on COCO dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Print model information\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Inference on Sample Images\n",
    "\n",
    "We’ll test YOLO on a sample image from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Sample image\n",
    "url = 'https://ultralytics.com/images/zidane.jpg'\n",
    "img = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Run inference\n",
    "results = model(img)\n",
    "\n",
    "# Display results\n",
    "results.show()\n",
    "\n",
    "# Print detections\n",
    "results.pandas().xyxy[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll see bounding boxes and labels like **person**, **sports ball**, etc., drawn directly on the image.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Run YOLO on Your Own Images\n",
    "\n",
    "You can upload your own image and test detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# Replace with your uploaded filename\n",
    "# img = 'your_image.jpg'\n",
    "# results = model(img)\n",
    "# results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Training YOLOv5 on Custom Data\n",
    "\n",
    "YOLO can be trained on your own dataset with images + label files in the **YOLO format**.\n",
    "\n",
    "Each label file corresponds to an image and contains:\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "All coordinates are **normalized (0–1)**.\n",
    "\n",
    "### Example: data.yaml\n",
    "```yaml\n",
    "train: ../data/images/train\n",
    "val: ../data/images/val\n",
    "nc: 3\n",
    "names: ['cat', 'dog', 'person']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: training command (run in shell)\n",
    "# !python train.py --img 640 --batch 16 --epochs 50 --data data.yaml --weights yolov5s.pt --name custom_yolo\n",
    "\n",
    "# After training, check results in runs/train/custom_yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Evaluating Model Performance\n",
    "\n",
    "YOLO reports multiple metrics:\n",
    "- **Precision**: Fraction of correct detections\n",
    "- **Recall**: Fraction of true objects detected\n",
    "- **mAP@.5**: Mean Average Precision at IoU threshold 0.5\n",
    "- **mAP@.5:.95**: Average over multiple IoU thresholds\n",
    "\n",
    "You can visualize results via the training logs or exported plots in `runs/train/exp*/results.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ Saving and Loading Models\n",
    "\n",
    "Once trained, you can save and reload your model easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'yolov5s_custom.pt')\n",
    "\n",
    "# Load later\n",
    "# model.load_state_dict(torch.load('yolov5s_custom.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ Exporting Model for Deployment\n",
    "\n",
    "YOLOv5 supports exporting models for different platforms:\n",
    "- **TorchScript**: PyTorch native\n",
    "- **ONNX**: Cross-framework\n",
    "- **CoreML**: iOS devices\n",
    "- **TensorRT**: NVIDIA inference\n",
    "\n",
    "```python\n",
    "# Export example\n",
    "# !python export.py --weights yolov5s.pt --include onnx coreml\n",
    "```\n",
    "\n",
    "This allows you to deploy YOLO models in production, mobile apps, or embedded devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "- YOLO = real-time object detection framework\n",
    "- Single forward pass predicts bounding boxes + class labels\n",
    "- YOLOv5 is easy to use via PyTorch Hub or CLI\n",
    "- Supports custom data training, evaluation, and deployment\n",
    "\n",
    "---\n",
    "**Next:** `12-Instance_Segmentation_Basics.ipynb` → Learn how segmentation extends detection by identifying **pixel-level** object boundaries.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

